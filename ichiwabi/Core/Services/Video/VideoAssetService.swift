import Foundation
import AVFoundation
import UIKit
import FirebaseStorage

enum VideoAssetError: LocalizedError {
    case assetNotFound
    case invalidAsset
    case loadFailed(Error)
    case exportFailed(Error)
    case downloadFailed
    
    var errorDescription: String? {
        switch self {
        case .assetNotFound:
            return "Base video asset not found"
        case .invalidAsset:
            return "Invalid video asset"
        case .loadFailed(let error):
            return "Failed to load video asset: \(error.localizedDescription)"
        case .exportFailed(let error):
            return "Failed to export video: \(error.localizedDescription)"
        case .downloadFailed:
            return "Failed to download video"
        }
    }
}

actor VideoAssetService {
    // MARK: - Properties
    private var baseVideoAssets: [DreamVideoStyle: AVAsset] = [:]
    
    @MainActor
    private static let sharedWatermarkService = WatermarkService.shared
    
    // MARK: - Initialization
    init() {
        // We'll load videos on demand instead of at init
    }
    
    // Helper to access watermark service safely
    @MainActor
    private func getWatermarkService() -> WatermarkService {
        return Self.sharedWatermarkService
    }
    
    // MARK: - Asset Loading
    private func loadBaseVideo(for style: DreamVideoStyle) -> AVAsset? {
        let assetName: String
        switch style {
        case .realistic:
            assetName = "DreamBaseImageRealistic"
        case .animated:
            assetName = "DreamBaseImageAnimated"
        case .cursed:
            assetName = "DreamBaseImageCursed"
        }
        
        print("\nüîç ==================== LOADING BASE VIDEO ====================")
        print("üîç Attempting to load video for style: \(style)")
        print("üîç Looking for asset named: \(assetName)")
        
        // Debug bundle information
        print("üîç Bundle details:")
        print("üîç - Bundle identifier: \(Bundle.main.bundleIdentifier ?? "none")")
        print("üîç - Bundle path: \(Bundle.main.bundlePath)")
        print("üîç - Resource path: \(String(describing: Bundle.main.resourcePath ?? "none"))")
        
        // First try Resources folder specifically
        print("\nüîç Trying Resources folder first...")
        if let resourcePath = Bundle.main.resourcePath {
            let resourcesPath = (resourcePath as NSString).appendingPathComponent("Resources")
            print("üîç Full Resources path: \(resourcesPath)")
            print("üîç Resources folder exists: \(FileManager.default.fileExists(atPath: resourcesPath))")
            
            let expectedVideoPath = (resourcesPath as NSString).appendingPathComponent("\(assetName).mp4")
            print("üîç Expected video path: \(expectedVideoPath)")
            print("üîç Video file exists: \(FileManager.default.fileExists(atPath: expectedVideoPath))")
        }
        
        if let videoURL = Bundle.main.url(forResource: assetName, withExtension: "mp4", subdirectory: "Resources") {
            print("‚úÖ Found video in Resources folder at: \(videoURL)")
            if FileManager.default.fileExists(atPath: videoURL.path) {
                print("‚úÖ File exists at path")
                return AVAsset(url: videoURL)
            } else {
                print("‚ùå File does not exist at path despite URL being found")
            }
        }
        
        // If not in Resources, try root bundle
        print("\nüîç Trying root bundle...")
        if let resourcePath = Bundle.main.resourcePath {
            let expectedVideoPath = (resourcePath as NSString).appendingPathComponent("\(assetName).mp4")
            print("üîç Expected video path: \(expectedVideoPath)")
            print("üîç Video file exists: \(FileManager.default.fileExists(atPath: expectedVideoPath))")
        }
        
        if let videoURL = Bundle.main.url(forResource: assetName, withExtension: "mp4") {
            print("‚úÖ Found video in root bundle at: \(videoURL)")
            if FileManager.default.fileExists(atPath: videoURL.path) {
                print("‚úÖ File exists at path")
                return AVAsset(url: videoURL)
            } else {
                print("‚ùå File does not exist at path despite URL being found")
            }
        }
        
        // If still not found, list all bundle contents for debugging
        if let resourcePath = Bundle.main.resourcePath {
            print("\nüîç Listing all files in resource path:")
            let fileManager = FileManager.default
            do {
                let items = try fileManager.contentsOfDirectory(atPath: resourcePath)
                print("üîç Found \(items.count) items:")
                items.forEach { item in
                    print("üîç - \(item)")
                }
                
                // Check Resources folder specifically
                let resourcesPath = (resourcePath as NSString).appendingPathComponent("Resources")
                if fileManager.fileExists(atPath: resourcesPath) {
                    print("\nüîç Contents of Resources folder:")
                    let resourceItems = try fileManager.contentsOfDirectory(atPath: resourcesPath)
                    print("üîç Found \(resourceItems.count) items:")
                    resourceItems.forEach { item in
                        print("üîç - \(item)")
                    }
                } else {
                    print("\n‚ùå Resources folder not found at: \(resourcesPath)")
                }
            } catch {
                print("‚ùå Error listing directory: \(error)")
            }
        }
        
        print("\n‚ùå Video not found in any location")
        print("‚ùå Searched for: \(assetName).mp4")
        print("üîç ==================== END LOADING ====================\n")
        return nil
    }
    
    // MARK: - Public Methods
    func getBaseVideoAsset(for style: DreamVideoStyle) throws -> AVAsset {
        // Return cached asset if available
        if let asset = baseVideoAssets[style] {
            return asset
        }
        
        // Load and cache the asset
        if let asset = loadBaseVideo(for: style) {
            baseVideoAssets[style] = asset
            return asset
        }
        
        throw VideoAssetError.assetNotFound
    }
    
    func getVideoDuration(for style: DreamVideoStyle) async throws -> TimeInterval {
        let asset = try getBaseVideoAsset(for: style)
        let duration = try await asset.load(.duration)
        return duration.seconds
    }
    
    // MARK: - Video Processing
    func createVideoWithAudio(audioURL: URL, duration: TimeInterval, style: DreamVideoStyle) async throws -> URL {
        return try await Task.detached { [self] () -> URL in
            print("\n‚≠êÔ∏è STEP 1: Starting video creation")
            print("‚≠êÔ∏è Audio URL: \(audioURL)")
            print("‚≠êÔ∏è Duration: \(duration)")
            print("‚≠êÔ∏è Style: \(style)")
            
            // Configure audio session first
            print("\n‚≠êÔ∏è STEP 2: Configuring audio session")
            let audioSession = AVAudioSession.sharedInstance()
            try audioSession.setCategory(.playback, mode: .default, options: [])
            try audioSession.setActive(true)
            print("‚≠êÔ∏è Audio session configured")
            
            // Get base video
            print("\n‚≠êÔ∏è STEP 3: Loading base video asset")
            let baseAsset = try await getBaseVideoAsset(for: style)
            print("‚≠êÔ∏è Base asset loaded successfully")
            
            // Create video-only composition first
            print("\n‚≠êÔ∏è STEP 4: Creating video composition")
            let composition = AVMutableComposition()
            
            // Create video track
            guard let videoTrack = composition.addMutableTrack(
                withMediaType: .video,
                preferredTrackID: kCMPersistentTrackID_Invalid
            ) else {
                print("‚ùå Failed to create video track")
                throw VideoAssetError.invalidAsset
            }
            
            // Load video track
            guard let baseVideoTrack = try await baseAsset.loadTracks(withMediaType: .video).first else {
                print("‚ùå No video track found in base asset")
                throw VideoAssetError.invalidAsset
            }
            
            // Calculate time ranges
            print("\n‚≠êÔ∏è STEP 5: Calculating durations")
            let videoDuration = try await baseAsset.load(.duration)
            let targetDuration = CMTime(seconds: duration, preferredTimescale: 600)
            print("‚≠êÔ∏è Video duration: \(videoDuration.seconds)s")
            print("‚≠êÔ∏è Target duration: \(targetDuration.seconds)s")
            
            // Loop video to match target duration
            print("\n‚≠êÔ∏è STEP 6: Creating looped video")
            var currentTime = CMTime.zero
            while currentTime < targetDuration {
                let remainingTime = targetDuration - currentTime
                let insertDuration = min(remainingTime, videoDuration)
                
                try videoTrack.insertTimeRange(
                    CMTimeRange(start: .zero, duration: insertDuration),
                    of: baseVideoTrack,
                    at: currentTime
                )
                
                currentTime = CMTimeAdd(currentTime, insertDuration)
            }
            
            // Export video-only composition first
            print("\n‚≠êÔ∏è STEP 7: Exporting video-only composition")
            let videoOnlyURL = FileManager.default.temporaryDirectory.appendingPathComponent("\(UUID().uuidString)_video.mp4")
            
            guard let exportSession = AVAssetExportSession(
                asset: composition,
                presetName: AVAssetExportPreset1280x720
            ) else {
                print("‚ùå Failed to create export session")
                throw VideoAssetError.invalidAsset
            }
            
            exportSession.outputURL = videoOnlyURL
            exportSession.outputFileType = .mp4
            exportSession.shouldOptimizeForNetworkUse = true
            
            print("‚≠êÔ∏è Starting video-only export")
            await exportSession.export()
            guard exportSession.status == .completed else {
                if let error = exportSession.error {
                    print("‚ùå Export failed with error: \(error)")
                    print("‚ùå Error details: \(error.localizedDescription)")
                    let nsError = error as NSError
                    print("‚ùå Domain: \(nsError.domain)")
                    print("‚ùå Code: \(nsError.code)")
                    if let underlyingError = nsError.userInfo[NSUnderlyingErrorKey] as? NSError {
                        print("‚ùå Underlying error: \(underlyingError)")
                    }
                }
                throw VideoAssetError.exportFailed(exportSession.error ?? NSError(domain: "VideoAsset", code: -1))
            }
            
            // Now create a new composition with both video and audio
            print("\n‚≠êÔ∏è STEP 8: Creating final composition with audio")
            let finalComposition = AVMutableComposition()
            
            // Add video track
            guard let finalVideoTrack = finalComposition.addMutableTrack(
                withMediaType: .video,
                preferredTrackID: kCMPersistentTrackID_Invalid
            ) else {
                print("‚ùå Failed to create final video track")
                throw VideoAssetError.invalidAsset
            }
            
            // Add audio track
            guard let finalAudioTrack = finalComposition.addMutableTrack(
                withMediaType: .audio,
                preferredTrackID: kCMPersistentTrackID_Invalid
            ) else {
                print("‚ùå Failed to create final audio track")
                throw VideoAssetError.invalidAsset
            }
            
            // Load the exported video
            let exportedVideoAsset = AVAsset(url: videoOnlyURL)
            let audioAsset = AVAsset(url: audioURL)
            
            // Get source tracks
            guard let sourceVideoTrack = try await exportedVideoAsset.loadTracks(withMediaType: .video).first,
                  let sourceAudioTrack = try await audioAsset.loadTracks(withMediaType: .audio).first else {
                print("‚ùå Failed to load source tracks")
                throw VideoAssetError.invalidAsset
            }
            
            // Insert tracks
            print("‚≠êÔ∏è Inserting final video and audio tracks")
            try finalVideoTrack.insertTimeRange(
                CMTimeRange(start: .zero, duration: targetDuration),
                of: sourceVideoTrack,
                at: .zero
            )
            
            try finalAudioTrack.insertTimeRange(
                CMTimeRange(start: .zero, duration: targetDuration),
                of: sourceAudioTrack,
                at: .zero
            )
            
            // Export final composition
            print("\n‚≠êÔ∏è STEP 9: Exporting final composition")
            let finalURL = FileManager.default.temporaryDirectory.appendingPathComponent("\(UUID().uuidString)_final.mp4")
            
            guard let finalExportSession = AVAssetExportSession(
                asset: finalComposition,
                presetName: AVAssetExportPreset1280x720
            ) else {
                print("‚ùå Failed to create final export session")
                throw VideoAssetError.invalidAsset
            }
            
            finalExportSession.outputURL = finalURL
            finalExportSession.outputFileType = .mp4
            finalExportSession.shouldOptimizeForNetworkUse = true
            
            // Use less demanding audio settings
            if #available(iOS 15.0, *) {
                finalExportSession.audioTimePitchAlgorithm = .timeDomain
            } else {
                finalExportSession.audioTimePitchAlgorithm = .lowQualityZeroLatency
            }
            finalExportSession.audioMix = nil
            
            print("‚≠êÔ∏è Starting final export")
            await finalExportSession.export()
            guard finalExportSession.status == .completed else {
                if let error = finalExportSession.error {
                    print("‚ùå Export failed with error: \(error)")
                    print("‚ùå Error details: \(error.localizedDescription)")
                    let nsError = error as NSError
                    print("‚ùå Domain: \(nsError.domain)")
                    print("‚ùå Code: \(nsError.code)")
                    if let underlyingError = nsError.userInfo[NSUnderlyingErrorKey] as? NSError {
                        print("‚ùå Underlying error: \(underlyingError)")
                    }
                }
                throw VideoAssetError.exportFailed(finalExportSession.error ?? NSError(domain: "VideoAsset", code: -1))
            }
            
            // Clean up intermediate file
            try? FileManager.default.removeItem(at: videoOnlyURL)
            
            return finalURL
        }.value
    }
    
    // MARK: - AI Video Processing
    func createVideoWithAIAndAudio(
        replicateVideoURL: URL,
        audioURL: URL,
        userId: String,
        dreamId: String,
        style: DreamVideoStyle,
        title: String? = nil
    ) async throws -> (videoURL: URL, audioURL: URL, localPath: String) {
        print("\nüé¨ ==================== CREATING AI VIDEO WITH AUDIO ====================")
        print("üé¨ Replicate URL: \(replicateVideoURL)")
        print("üé¨ Audio URL: \(audioURL)")
        print("üé¨ Title: \(title ?? "none")")
        
        // Debug audio session state
        print("\nüîä ==================== AUDIO SESSION DEBUG ====================")
        let audioSession = AVAudioSession.sharedInstance()
        print("üîä Current audio session state:")
        print("üîä - Category: \(audioSession.category.rawValue)")
        print("üîä - Mode: \(audioSession.mode.rawValue)")
        print("üîä - Sample rate: \(audioSession.sampleRate)")
        print("üîä - Preferred IO buffer duration: \(audioSession.preferredIOBufferDuration)")
        print("üîä - Input available: \(audioSession.isInputAvailable)")
        print("üîä - Other audio playing: \(audioSession.isOtherAudioPlaying)")
        
        // Configure audio session
        do {
            print("üîä Configuring audio session...")
            try audioSession.setCategory(.playback, mode: .default, options: [])
            try audioSession.setActive(true)
            print("üîä Audio session configured successfully")
            print("üîä - New category: \(audioSession.category.rawValue)")
            print("üîä - New mode: \(audioSession.mode.rawValue)")
        } catch {
            print("‚ùå Failed to configure audio session: \(error)")
            if let avError = error as? AVError {
                print("‚ùå AVError code: \(avError.code.rawValue)")
            }
        }
        
        // Debug audio file
        print("\nüîä Analyzing audio file...")
        let audioAsset = AVAsset(url: audioURL)
        let audioExists = FileManager.default.fileExists(atPath: audioURL.path)
        print("üîä Audio file exists: \(audioExists)")
        if audioExists {
            let attributes = try? FileManager.default.attributesOfItem(atPath: audioURL.path)
            print("üîä Audio file size: \(attributes?[.size] ?? 0) bytes")
        }
        
        // Load and check audio tracks
        if let audioTracks = try? await audioAsset.loadTracks(withMediaType: .audio) {
            print("üîä Audio tracks found: \(audioTracks.count)")
            for (index, track) in audioTracks.enumerated() {
                print("üîä Track \(index):")
                print("üîä - Format descriptions: \(String(describing: try? await track.load(.formatDescriptions)))")
                if let formatDescriptions = try? await track.load(.formatDescriptions) as [CMFormatDescription],
                   let firstFormat = formatDescriptions.first,
                   let basicDescription = CMAudioFormatDescriptionGetStreamBasicDescription(firstFormat) {
                    print("üîä - Sample rate: \(basicDescription.pointee.mSampleRate)")
                    print("üîä - Channels: \(basicDescription.pointee.mChannelsPerFrame)")
                    print("üîä - Bytes per frame: \(basicDescription.pointee.mBytesPerFrame)")
                    print("üîä - Format ID: \(basicDescription.pointee.mFormatID)")
                }
            }
        } else {
            print("‚ùå Failed to load audio tracks")
        }
        print("üîä ==================== END AUDIO DEBUG ====================\n")
        
        // First, upload the audio file to Firebase Storage
        let audioRef = Storage.storage().reference().child("users/\(userId)/audio/\(dreamId).m4a")
        let audioMetadata = StorageMetadata()
        audioMetadata.contentType = "audio/m4a"
        
        print("üé¨ Uploading audio file to Firebase Storage")
        _ = try await audioRef.putFileAsync(from: audioURL, metadata: audioMetadata)
        let audioDownloadURL = try await audioRef.downloadURL()
        print("üé¨ Audio file uploaded successfully: \(audioDownloadURL)")
        
        // Get audio duration
        let audioDuration = try await audioAsset.load(.duration).seconds
        print("üé¨ Audio duration: \(audioDuration) seconds")
        
        // Download the Replicate video
        let (tempURL, response) = try await URLSession.shared.download(from: replicateVideoURL)
        guard let httpResponse = response as? HTTPURLResponse,
              httpResponse.statusCode == 200 else {
            throw VideoAssetError.downloadFailed
        }
        
        // Move to a temporary file
        let temporaryDirectory = FileManager.default.temporaryDirectory
        let downloadedVideoURL = temporaryDirectory.appendingPathComponent(UUID().uuidString + ".mp4")
        try? FileManager.default.removeItem(at: downloadedVideoURL)
        try FileManager.default.moveItem(at: tempURL, to: downloadedVideoURL)
        print("üé¨ Replicate video downloaded to: \(downloadedVideoURL)")
        
        // STEP 1: First create a looped video without audio
        print("üé¨ STEP 1: Creating looped video composition")
        let loopedVideoURL = try await createLoopedVideo(
            from: downloadedVideoURL,
            targetDuration: audioDuration
        )
        print("üé¨ Looped video created successfully")
        
        // STEP 2: Add audio to the looped video
        print("üé¨ STEP 2: Adding audio to looped video")
        let videoWithAudioURL = try await addAudioToVideo(
            videoURL: loopedVideoURL,
            audioURL: audioURL,
            targetDuration: audioDuration,
            title: title
        )
        print("üé¨ Audio added successfully")
        
        // Clean up intermediate file
        try? FileManager.default.removeItem(at: loopedVideoURL)
        
        // Upload to Firebase Storage
        print("üé¨ Uploading final video to Firebase")
        let videoRef = Storage.storage().reference().child("dreams/\(userId)/\(dreamId).mp4")
        let metadata = StorageMetadata()
        metadata.contentType = "video/mp4"
        
        _ = try await videoRef.putFileAsync(from: videoWithAudioURL, metadata: metadata)
        let downloadURL = try await videoRef.downloadURL()
        
        print("üé¨ Video uploaded successfully")
        print("üé¨ Download URL: \(downloadURL)")
        print("üé¨ Audio URL: \(audioDownloadURL)")
        print("üé¨ ==================== END CREATING AI VIDEO WITH AUDIO ====================\n")
        
        // Clean up temporary files
        try? FileManager.default.removeItem(at: downloadedVideoURL)
        
        return (downloadURL, audioDownloadURL, videoWithAudioURL.lastPathComponent)
    }
    
    // Helper function to create looped video without audio
    private func createLoopedVideo(from videoURL: URL, targetDuration: Double) async throws -> URL {
        return try await Task.detached { () -> URL in
            let asset = AVAsset(url: videoURL)
            let composition = AVMutableComposition()
            
            guard let compositionVideoTrack = composition.addMutableTrack(
                withMediaType: .video,
                preferredTrackID: kCMPersistentTrackID_Invalid
            ),
            let sourceVideoTrack = try await asset.loadTracks(withMediaType: .video).first else {
                throw VideoAssetError.invalidAsset
            }
            
            let videoDuration = try await asset.load(.duration)
            var currentTime = CMTime.zero
            let targetTime = CMTime(seconds: targetDuration, preferredTimescale: 600)
            
            while currentTime < targetTime {
                let remainingTime = targetTime - currentTime
                let insertDuration = min(remainingTime, videoDuration)
                
                try compositionVideoTrack.insertTimeRange(
                    CMTimeRange(start: .zero, duration: insertDuration),
                    of: sourceVideoTrack,
                    at: currentTime
                )
                
                currentTime = CMTimeAdd(currentTime, insertDuration)
            }
            
            // Export looped video
            let loopedURL = FileManager.default.temporaryDirectory
                .appendingPathComponent("looped_\(UUID().uuidString).mp4")
            
            guard let exportSession = AVAssetExportSession(
                asset: composition,
                presetName: AVAssetExportPresetHighestQuality
            ) else {
                throw VideoAssetError.invalidAsset
            }
            
            exportSession.outputURL = loopedURL
            exportSession.outputFileType = .mp4
            exportSession.shouldOptimizeForNetworkUse = true
            
            await exportSession.export()
            guard exportSession.status == .completed else {
                if let error = exportSession.error {
                    print("‚ùå Export failed with error: \(error)")
                    print("‚ùå Error details: \(error.localizedDescription)")
                    let nsError = error as NSError
                    print("‚ùå Domain: \(nsError.domain)")
                    print("‚ùå Code: \(nsError.code)")
                    if let underlyingError = nsError.userInfo[NSUnderlyingErrorKey] as? NSError {
                        print("‚ùå Underlying error: \(underlyingError)")
                    }
                }
                throw VideoAssetError.exportFailed(exportSession.error ?? NSError(domain: "VideoAsset", code: -1))
            }
            
            return loopedURL
        }.value
    }
    
    // Helper function to add audio to video
    private func addAudioToVideo(videoURL: URL, audioURL: URL, targetDuration: Double, title: String?) async throws -> URL {
        // Create everything in a single detached task to avoid crossing actor boundaries with non-Sendable types
        return try await Task.detached { () -> URL in
            let videoAsset = AVAsset(url: videoURL)
            let audioAsset = AVAsset(url: audioURL)
            
            // Create composition
            let composition = AVMutableComposition()
            
            // Add video track
            guard let compositionVideoTrack = composition.addMutableTrack(
                withMediaType: .video,
                preferredTrackID: kCMPersistentTrackID_Invalid
            ),
            let sourceVideoTrack = try await videoAsset.loadTracks(withMediaType: .video).first else {
                throw VideoAssetError.invalidAsset
            }
            
            // Add audio track
            guard let compositionAudioTrack = composition.addMutableTrack(
                withMediaType: .audio,
                preferredTrackID: kCMPersistentTrackID_Invalid
            ),
            let sourceAudioTrack = try await audioAsset.loadTracks(withMediaType: .audio).first else {
                throw VideoAssetError.invalidAsset
            }
            
            // Insert video and audio
            let timeRange = CMTimeRange(
                start: .zero,
                duration: CMTime(seconds: targetDuration, preferredTimescale: 600)
            )
            
            try compositionVideoTrack.insertTimeRange(timeRange, of: sourceVideoTrack, at: .zero)
            try compositionAudioTrack.insertTimeRange(timeRange, of: sourceAudioTrack, at: .zero)
            
            // Create watermark composition
            let watermarkComposition: AVMutableVideoComposition = try await Task { @MainActor in
                let watermarkService = Self.sharedWatermarkService
                return try await watermarkService.applyWatermark(
                    to: composition,
                    date: Date(),
                    title: title
                )
            }.value
            
            // Export final video
            let finalURL = FileManager.default.temporaryDirectory
                .appendingPathComponent("final_\(UUID().uuidString).mp4")
            
            guard let exportSession = AVAssetExportSession(
                asset: composition,
                presetName: AVAssetExportPreset1280x720
            ) else {
                throw VideoAssetError.invalidAsset
            }
            
            exportSession.outputURL = finalURL
            exportSession.outputFileType = .mp4
            exportSession.shouldOptimizeForNetworkUse = true
            exportSession.videoComposition = watermarkComposition
            
            if #available(iOS 15.0, *) {
                exportSession.audioTimePitchAlgorithm = .timeDomain
            } else {
                exportSession.audioTimePitchAlgorithm = .lowQualityZeroLatency
            }
            exportSession.audioMix = nil
            
            await exportSession.export()
            guard exportSession.status == .completed else {
                throw VideoAssetError.exportFailed(exportSession.error ?? NSError(domain: "VideoAsset", code: -1))
            }
            
            // Clean up
            try? FileManager.default.removeItem(at: videoURL)
            
            return finalURL
        }.value
    }
    
    private func createReversedVideoTrack(from track: AVAssetTrack, duration: CMTime) async throws -> AVAssetTrack {
        let composition = AVMutableComposition()
        guard let compositionTrack = composition.addMutableTrack(
            withMediaType: .video,
            preferredTrackID: kCMPersistentTrackID_Invalid
        ) else {
            throw VideoAssetError.invalidAsset
        }
        
        // Create reversed transform
        var transform = try await track.load(.preferredTransform)
        transform.a *= -1 // Reverse horizontal direction
        
        // Insert time range with reversed transform
        try compositionTrack.insertTimeRange(
            CMTimeRange(start: .zero, duration: duration),
            of: track,
            at: .zero
        )
        compositionTrack.preferredTransform = transform
        
        return compositionTrack
    }
} 
